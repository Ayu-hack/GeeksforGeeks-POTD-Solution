{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Music Generator based on Genre using VanillaGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to dataset\n",
    "DATA_PATH = r'H:\\Deep Learning\\Music Generator by Genre\\GTZAN Data\\genres_original'\n",
    "\n",
    "# Define fixed length for spectrograms (e.g., 128 time frames)\n",
    "FIXED_LENGTH = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and process Mel-Spectrograms for a specific genre\n",
    "def load_data(genre, sr=22050, n_fft=2048, hop_length=512, n_mels=128):\n",
    "    genre_path = os.path.join(DATA_PATH, genre)\n",
    "    mel_spectrograms = []\n",
    "\n",
    "    for file_name in os.listdir(genre_path):\n",
    "        file_path = os.path.join(genre_path, file_name)\n",
    "        if file_name.endswith('.wav'):\n",
    "            y, _ = librosa.load(file_path, sr=sr)\n",
    "            mel = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n",
    "            mel_db = librosa.power_to_db(mel, ref=np.max)\n",
    "\n",
    "            # Fix the shape of spectrograms (padding or truncating)\n",
    "            if mel_db.shape[1] < FIXED_LENGTH:\n",
    "                # Pad with zeros if shorter than FIXED_LENGTH\n",
    "                pad_width = FIXED_LENGTH - mel_db.shape[1]\n",
    "                mel_db = np.pad(mel_db, ((0, 0), (0, pad_width)), mode='constant')\n",
    "            else:\n",
    "                # Truncate if longer than FIXED_LENGTH\n",
    "                mel_db = mel_db[:, :FIXED_LENGTH]\n",
    "\n",
    "            mel_spectrograms.append(mel_db)\n",
    "\n",
    "    return np.array(mel_spectrograms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(mel_spectrograms):\n",
    "    mel_spectrograms = (mel_spectrograms - mel_spectrograms.min()) / (mel_spectrograms.max() - mel_spectrograms.min())\n",
    "    mel_spectrograms = mel_spectrograms.astype('float32')\n",
    "    mel_spectrograms = mel_spectrograms[..., np.newaxis]\n",
    "    return mel_spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classical Genre Mel Spectrograms shape: (100, 128, 1000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load data for a specific genre\n",
    "genre = \"classical\"  # Change genre as needed\n",
    "mel_spectrograms = load_data(genre)\n",
    "mel_spectrograms = preprocess_data(mel_spectrograms)\n",
    "\n",
    "print(f'Classical Genre Mel Spectrograms shape: {mel_spectrograms.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 1000, 1)\n"
     ]
    }
   ],
   "source": [
    "# GAN Parameters\n",
    "latent_dim = 100\n",
    "input_shape = mel_spectrograms.shape[1:]\n",
    "\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Generator Model\n",
    "\n",
    "def build_generator(latent_dim):\n",
    "    model = tf.keras.Sequential([\n",
    "\n",
    "        # project noise vector to initial feature map\n",
    "        layers.Dense(512 * 4 *4, input_dim=latent_dim),\n",
    "        layers.Reshape((4,4,512)),\n",
    "\n",
    "        # Upsampling layers with increasing resolution\n",
    "        layers.Conv2DTranspose(256, kernel_size=5, strides=(2, 2), padding='same', activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "\n",
    "        layers.Conv2DTranspose(128, kernel_size=5, strides=(2, 5), padding='same', activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "\n",
    "        layers.Conv2DTranspose(64, kernel_size=5, strides=(2, 5), padding='same', activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "\n",
    "        layers.Conv2DTranspose(32, kernel_size=3, strides=(2, 5), padding='same', activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "\n",
    "\n",
    "        # Output layer (mel-spectrogram grayscale image)\n",
    "        layers.Conv2DTranspose(1, kernel_size=5, strides=(2,1), padding='same', activation='tanh')\n",
    "\n",
    "    ])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Discriminator Model\n",
    "\n",
    "def build_discriminator(input_shape):\n",
    "    model = tf.keras.Sequential([\n",
    "        # First convolutional layer\n",
    "        layers.Conv2D(64, kernel_size=5, strides=2, padding='same', input_shape=input_shape),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Dropout(0.3),\n",
    "\n",
    "        # Second convolutional layer\n",
    "        layers.Conv2D(128, kernel_size=5, strides=2, padding='same'),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Dropout(0.3),\n",
    "\n",
    "        # Third convolutional layer\n",
    "        layers.Conv2D(256, kernel_size=5, strides=2, padding='same'),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Dropout(0.3),\n",
    "\n",
    "        # Fourth convolutional layer\n",
    "        layers.Conv2D(512, kernel_size=5, strides=2, padding='same'),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Dropout(0.3),\n",
    "\n",
    "        layers.Flatten(),\n",
    "\n",
    "        # Dense layers for classification\n",
    "        layers.Dense(1024),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Dropout(0.5),\n",
    "\n",
    "        layers.Dense(1, activation='sigmoid')  # Binary classification (real/fake)\n",
    "    ])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Generator and Discriminator\n",
    "generator = build_generator(latent_dim)\n",
    "discriminator = build_discriminator(input_shape)\n",
    "\n",
    "# Compile Discriminator\n",
    "discriminator.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), \n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), \n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build GAN Model\n",
    "discriminator.trainable = False\n",
    "gan_input = layers.Input(shape=(latent_dim,))\n",
    "fake_image = generator(gan_input)\n",
    "gan_output = discriminator(fake_image)\n",
    "gan = tf.keras.Model(gan_input, gan_output)\n",
    "gan.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), \n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_24\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_24\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sequential_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,149,825</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sequential_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │   <span style=\"color: #00af00; text-decoration-color: #00af00\">268,546,561</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_26 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sequential_16 (\u001b[38;5;33mSequential\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │     \u001b[38;5;34m5,149,825\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sequential_17 (\u001b[38;5;33mSequential\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │   \u001b[38;5;34m268,546,561\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">273,696,386</span> (1.02 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m273,696,386\u001b[0m (1.02 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,148,865</span> (19.64 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,148,865\u001b[0m (19.64 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">268,547,521</span> (1.00 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m268,547,521\u001b[0m (1.00 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Function\n",
    "def train_gan(generator, discriminator, gan, data, epochs, batch_size):\n",
    "    half_batch = batch_size // 2\n",
    "    for epoch in range(epochs):\n",
    "        # Train Discriminator\n",
    "        idx = np.random.randint(0, data.shape[0], half_batch)\n",
    "        real_images = tf.convert_to_tensor(data[idx], dtype=tf.float32)\n",
    "        real_labels = np.ones((half_batch, 1))\n",
    "\n",
    "        noise = np.random.normal(0, 1, (half_batch, latent_dim))\n",
    "        fake_images = generator.predict(noise)\n",
    "        fake_labels = np.zeros((half_batch, 1))\n",
    "\n",
    "        d_loss_real = discriminator.train_on_batch(real_images, real_labels)\n",
    "        d_loss_fake = discriminator.train_on_batch(fake_images, fake_labels)\n",
    "\n",
    "        # Train Generator\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        misleading_labels = np.ones((batch_size, 1))\n",
    "        g_loss = gan.train_on_batch(noise, misleading_labels)\n",
    "\n",
    "        # Log losses\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}/{epochs} | D Loss: {d_loss_real[0]+d_loss_fake[0]:.4f} | G Loss: {g_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613ms/step\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'update_state'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[105], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train the GAN\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrain_gan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscriminator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmel_spectrograms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[104], line 14\u001b[0m, in \u001b[0;36mtrain_gan\u001b[1;34m(generator, discriminator, gan, data, epochs, batch_size)\u001b[0m\n\u001b[0;32m     11\u001b[0m fake_images \u001b[38;5;241m=\u001b[39m generator\u001b[38;5;241m.\u001b[39mpredict(noise)\n\u001b[0;32m     12\u001b[0m fake_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((half_batch, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m---> 14\u001b[0m d_loss_real \u001b[38;5;241m=\u001b[39m \u001b[43mdiscriminator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreal_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m d_loss_fake \u001b[38;5;241m=\u001b[39m discriminator\u001b[38;5;241m.\u001b[39mtrain_on_batch(fake_images, fake_labels)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Train Generator\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:598\u001b[0m, in \u001b[0;36mTensorFlowTrainer.train_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, return_dict)\u001b[0m\n\u001b[0;32m    595\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdata\u001b[39m():\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m (x, y, sample_weight)\n\u001b[1;32m--> 598\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    599\u001b[0m logs \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mmap_structure(\u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39marray(x), logs)\n\u001b[0;32m    600\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict:\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:224\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps_per_execution), iterator\n\u001b[0;32m    223\u001b[0m     ):\n\u001b[1;32m--> 224\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[43mone_step_on_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:110\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.one_step_on_data\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;129m@tf\u001b[39m\u001b[38;5;241m.\u001b[39mautograph\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mdo_not_convert\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mone_step_on_data\u001b[39m(data):\n\u001b[0;32m    109\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Runs a single training step on a batch of data.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 110\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[0;32m    112\u001b[0m         outputs,\n\u001b[0;32m    113\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy,\n\u001b[0;32m    114\u001b[0m         reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    115\u001b[0m     )\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:66\u001b[0m, in \u001b[0;36mTensorFlowTrainer.train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     58\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(x)\n\u001b[0;32m     59\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_loss(\n\u001b[0;32m     60\u001b[0m     x\u001b[38;5;241m=\u001b[39mx,\n\u001b[0;32m     61\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     65\u001b[0m )\n\u001b[1;32m---> 66\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_loss_tracker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_state\u001b[49m(\n\u001b[0;32m     67\u001b[0m     loss, sample_weight\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mshape(tree\u001b[38;5;241m.\u001b[39mflatten(x)[\u001b[38;5;241m0\u001b[39m])[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     68\u001b[0m )\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mscale_loss(loss)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'update_state'"
     ]
    }
   ],
   "source": [
    "# Train the GAN\n",
    "train_gan(generator, discriminator, gan, mel_spectrograms, epochs=50, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate New Audio\n",
    "def generate_audio(generator, latent_dim, sr=22050):\n",
    "    noise = np.random.normal(0, 1, (1, latent_dim))\n",
    "    generated_mel = generator.predict(noise)\n",
    "    generated_mel = generated_mel.squeeze()  # Remove extra dimensions\n",
    "    generated_mel = (generated_mel * 255).astype(np.uint8)  # Rescale\n",
    "\n",
    "    # Convert Mel-Spectrogram back to audio\n",
    "    mel_spectrogram = librosa.feature.inverse.mel_to_audio(generated_mel, sr=sr)\n",
    "    return mel_spectrogram\n",
    "\n",
    "# Example: Generate audio\n",
    "generated_audio = generate_audio(generator, latent_dim)\n",
    "librosa.output.write_wav('generated_audio.wav', generated_audio, sr=22050)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
